{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsum (the dumb inneficient way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumbsum(x, y, shapes):\n",
    "    '''\n",
    "    dumb implem for my own intuition building sake, with absolutely no value for real life use.\n",
    "    not vectorized, and do not handle splitting / merging / creating extra dim.\n",
    "    \n",
    "    the main idea is to:\n",
    "    1- generate nested loops for indexing for each dim in the output\n",
    "    2- generate nexted loops for summing everything else\n",
    "    e.g. 'a b c d e, a c e -> a d b'\n",
    "    for a in range(x.shape[0]):\n",
    "      for d in range(x.shape[3]):\n",
    "        for b in range(x.shape[1]):\n",
    "          tot = 0\n",
    "          for c in range(x.shape[2]):\n",
    "            for e in range(x.shape[4]):\n",
    "              tot += x[a, b, c, d, e] * y[a, c, e]\n",
    "          res[a, d, b] = tot\n",
    "\n",
    "    in practice I initialize res to a tensor of zero, and update it in place instead of accumulating in a tot\n",
    "    res[a, d, b] += x[a, b, c, d, e] * y[a, c, e]\n",
    "    '''\n",
    "    def split_shape(shape):\n",
    "        return [x for x in shape.split(' ') if x]\n",
    "    def parse(shapes):\n",
    "        assert shapes.count(',') == 1\n",
    "        assert shapes.count('->') == 1\n",
    "        shapes, res_shape = shapes.split('->')\n",
    "        x_shape, y_shape = shapes.split(',')\n",
    "        x_shape, y_shape, res_shape = (split_shape(s) for s in (x_shape, y_shape, res_shape))\n",
    "        sum_shape = list(set(x_shape + y_shape) - set(res_shape))\n",
    "        assert set(res_shape).issubset(set(x_shape + y_shape))\n",
    "        return x_shape, y_shape, res_shape, sum_shape\n",
    "    def build_dim_lookup(t, t_shape, lookup=None):\n",
    "        if not lookup: lookup = {}\n",
    "        dims = t.shape\n",
    "        for dim, letter in zip(dims, t_shape):\n",
    "            assert lookup.get(letter, dim) == dim\n",
    "            lookup[letter] = dim\n",
    "        return lookup\n",
    "    def iterate(shape, sum_shape, fn, lookup, indexes):\n",
    "        if not shape:\n",
    "            iterate_sum(sum_shape[:], fn, lookup, indexes)\n",
    "            return\n",
    "        dim = shape.pop(-1)\n",
    "        # print(f'iterate over → {dim}')\n",
    "        for i in range(lookup[dim]):\n",
    "            indexes[dim] = i\n",
    "            iterate(shape[:], sum_shape, fn, lookup, indexes)\n",
    "    def iterate_sum(sum_shape, fn, lookup, indexes):\n",
    "        if not sum_shape:\n",
    "            fn(indexes)\n",
    "            return\n",
    "        dim = sum_shape.pop(-1)\n",
    "        # print(f'sum over → {dim}')\n",
    "        for i in range(lookup[dim]):\n",
    "            indexes[dim] = i\n",
    "            iterate_sum(sum_shape[:], fn, lookup, indexes)\n",
    "    def ind(t_shape, indexes):\n",
    "        return (indexes[dim] for dim in t_shape)\n",
    "    def close_sum(x, y, res, x_shape, y_shape, res_shape):\n",
    "        def fn(indexes):\n",
    "            # print(f'res[{tuple(ind(res_shape, indexes))}] += x[{tuple(ind(x_shape, indexes))}] * y[{tuple(ind(y_shape, indexes))}]')\n",
    "            res[*ind(res_shape, indexes)] += x[*ind(x_shape, indexes)] * y[*ind(y_shape, indexes)]\n",
    "        return fn\n",
    "\n",
    "    x_shape, y_shape, res_shape, sum_shape = parse(shapes)\n",
    "    assert len(x_shape) == x.dim()\n",
    "    assert len(y_shape) == y.dim()\n",
    "    lookup = build_dim_lookup(x, x_shape)\n",
    "    lookup = build_dim_lookup(y, y_shape, lookup=lookup)\n",
    "    res = t.zeros(tuple(lookup[s] for s in res_shape))\n",
    "    fn = close_sum(x, y, res, x_shape, y_shape, res_shape)\n",
    "    iterate(res_shape[:], sum_shape[:], fn, lookup, {})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_test():\n",
    "    x = t.rand((4, 5))\n",
    "    y = t.rand((5, 3))\n",
    "    a = dumbsum(x, y, 'a b, b c -> a c')\n",
    "    b = x @ y\n",
    "    assert a.allclose(b)\n",
    "\n",
    "dumb_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def einops_test(x, y, pattern):\n",
    "    a = dumbsum(x, y, pattern)\n",
    "    b = einops.einsum(x, y, pattern)\n",
    "    assert a.allclose(b)\n",
    "\n",
    "x = t.rand((10, 5, 2, 3))\n",
    "y = t.rand((3, 10, 5, 7))\n",
    "einops_test(x, y, 'a b c d, d a b e -> b e c')\n",
    "einops_test(x, y, 'a b c d, d a b e -> a b c d e')\n",
    "einops_test(x, y, 'a b c d, d a b e -> e d c b a')\n",
    "einops_test(x, y, 'a b c d, d a b e -> a')\n",
    "einops_test(x, y, 'a b c d, d a b e ->')\n",
    "einops_test(x, y, 'a b c d, d a b e -> a e')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
