{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsum (the dumb inneficient way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recursion and loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumbsum(x, y, shapes):\n",
    "    '''\n",
    "    dumb implem for my own intuition building sake, with absolutely no value for real life use.\n",
    "    not vectorized, and do not handle splitting / merging / creating extra dim.\n",
    "    \n",
    "    the main idea is to:\n",
    "    1- generate nested loops for indexing for each dim in the output\n",
    "    2- generate nexted loops for summing everything else\n",
    "    e.g. 'a b c d e, a c e -> a d b'\n",
    "    for a in range(x.shape[0]):\n",
    "      for d in range(x.shape[3]):\n",
    "        for b in range(x.shape[1]):\n",
    "          tot = 0\n",
    "          for c in range(x.shape[2]):\n",
    "            for e in range(x.shape[4]):\n",
    "              tot += x[a, b, c, d, e] * y[a, c, e]\n",
    "          res[a, d, b] = tot\n",
    "\n",
    "    in practice I initialize res to a tensor of zero, and update it in place instead of accumulating in a tot\n",
    "    res[a, d, b] += x[a, b, c, d, e] * y[a, c, e]\n",
    "    '''\n",
    "    def split_shape(shape):\n",
    "        return [x for x in shape.split(' ') if x]\n",
    "    def parse(shapes):\n",
    "        assert shapes.count(',') == 1\n",
    "        assert shapes.count('->') == 1\n",
    "        shapes, res_shape = shapes.split('->')\n",
    "        x_shape, y_shape = shapes.split(',')\n",
    "        x_shape, y_shape, res_shape = (split_shape(s) for s in (x_shape, y_shape, res_shape))\n",
    "        sum_shape = list(set(x_shape + y_shape) - set(res_shape))\n",
    "        assert set(res_shape).issubset(set(x_shape + y_shape))\n",
    "        return x_shape, y_shape, res_shape, sum_shape\n",
    "    def build_dim_lookup(t, t_shape, lookup=None):\n",
    "        if not lookup: lookup = {}\n",
    "        dims = t.shape\n",
    "        for dim, letter in zip(dims, t_shape):\n",
    "            assert lookup.get(letter, dim) == dim\n",
    "            lookup[letter] = dim\n",
    "        return lookup\n",
    "    def iterate(shape, sum_shape, fn, lookup, indexes):\n",
    "        if not shape:\n",
    "            iterate_sum(sum_shape[:], fn, lookup, indexes)\n",
    "            return\n",
    "        dim = shape.pop(-1)\n",
    "        # print(f'iterate over → {dim}')\n",
    "        for i in range(lookup[dim]):\n",
    "            indexes[dim] = i\n",
    "            iterate(shape[:], sum_shape, fn, lookup, indexes)\n",
    "    def iterate_sum(sum_shape, fn, lookup, indexes):\n",
    "        if not sum_shape:\n",
    "            fn(indexes)\n",
    "            return\n",
    "        dim = sum_shape.pop(-1)\n",
    "        # print(f'sum over → {dim}')\n",
    "        for i in range(lookup[dim]):\n",
    "            indexes[dim] = i\n",
    "            iterate_sum(sum_shape[:], fn, lookup, indexes)\n",
    "    def ind(t_shape, indexes):\n",
    "        return (indexes[dim] for dim in t_shape)\n",
    "    def close_sum(x, y, res, x_shape, y_shape, res_shape):\n",
    "        def fn(indexes):\n",
    "            # print(f'res[{tuple(ind(res_shape, indexes))}] += x[{tuple(ind(x_shape, indexes))}] * y[{tuple(ind(y_shape, indexes))}]')\n",
    "            res[*ind(res_shape, indexes)] += x[*ind(x_shape, indexes)] * y[*ind(y_shape, indexes)]\n",
    "        return fn\n",
    "\n",
    "    x_shape, y_shape, res_shape, sum_shape = parse(shapes)\n",
    "    assert len(x_shape) == x.dim()\n",
    "    assert len(y_shape) == y.dim()\n",
    "    lookup = build_dim_lookup(x, x_shape)\n",
    "    lookup = build_dim_lookup(y, y_shape, lookup=lookup)\n",
    "    res = t.zeros(tuple(lookup[s] for s in res_shape))\n",
    "    fn = close_sum(x, y, res, x_shape, y_shape, res_shape)\n",
    "    iterate(res_shape[:], sum_shape[:], fn, lookup, {})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumbsum_vectorized(x, y, shapes):\n",
    "    '''\n",
    "    vectorize it, still do not handle splitting / merging / creating extra dim.\n",
    "    my vectorized also does not handle repeated dim (e.g. 'a a b, a a c -> a a').\n",
    "    \n",
    "    the main idea is to:\n",
    "    1- align the dimensions of x and y, completing the holes with fake `1` dimensions\n",
    "    2- multiply x and y\n",
    "    3- sum out the extra dims\n",
    "    e.g. 'a c d e, a c e -> a d b'\n",
    "    # align dims\n",
    "    x = reshape('a c d e -> a 1 c d e')\n",
    "    y = reshape('a c e   -> a 1 c 1 e')\n",
    "    # order dims\n",
    "    x = reshape('a 1 c d e -> a d 1 c e')\n",
    "    y = reshape('a 1 c 1 e -> a 1 1 c e')\n",
    "    # mult and sum\n",
    "    res = x * y\n",
    "    res = res.sum((3, 4))\n",
    "    '''\n",
    "    def split_shape(shape):\n",
    "        return [x for x in shape.split(' ') if x]\n",
    "    def parse(shapes):\n",
    "        assert shapes.count(',') == 1\n",
    "        assert shapes.count('->') == 1\n",
    "        shapes, res_shape = shapes.split('->')\n",
    "        x_shape, y_shape = shapes.split(',')\n",
    "        x_shape, y_shape, res_shape = (split_shape(s) for s in (x_shape, y_shape, res_shape))\n",
    "        sum_shape = list(set(x_shape + y_shape) - set(res_shape))\n",
    "        assert set(res_shape).issubset(set(x_shape + y_shape))\n",
    "        return x_shape, y_shape, res_shape, sum_shape\n",
    "    def build_dim_pos_lookup(t_shape):\n",
    "        return {letter: dim for dim, letter in enumerate(t_shape)}\n",
    "    def expand(t, t_shape, merged):\n",
    "        lookup = build_dim_pos_lookup(t_shape)\n",
    "        ind = len(lookup)\n",
    "        for dim in merged:\n",
    "            if dim not in lookup:\n",
    "                t = t.unsqueeze(-1)\n",
    "                lookup[dim] = ind\n",
    "                ind += 1\n",
    "        return t, lookup\n",
    "    def align(t, lookup, res_lookup):\n",
    "        # rely on dict being ordered (python >= 3.7)\n",
    "        permuted_dims = tuple(lookup[dim] for dim in res_lookup)\n",
    "        return t.permute(permuted_dims)\n",
    "    def dims_to_sum(res_shape, res_lookup):\n",
    "        return tuple(range(len(res_shape), len(res_lookup)))\n",
    "\n",
    "    x_shape, y_shape, res_shape, sum_shape = parse(shapes)\n",
    "    assert len(x_shape) == x.dim()\n",
    "    assert len(y_shape) == y.dim()\n",
    "    merged = set(x_shape + y_shape)\n",
    "    x, x_lookup = expand(x, x_shape, merged)\n",
    "    y, y_lookup = expand(y, y_shape, merged)\n",
    "    _, res_lookup = expand(t.zeros((0)), res_shape, merged)\n",
    "    x = align(x, x_lookup, res_lookup)\n",
    "    y = align(y, y_lookup, res_lookup)\n",
    "    res = x * y\n",
    "    dims = dims_to_sum(res_shape, res_lookup)\n",
    "    if dims: res = res.sum(dims)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_test():\n",
    "    x = t.rand((4, 5))\n",
    "    y = t.rand((5, 3))\n",
    "    pattern = 'a b, b c -> a c'\n",
    "    a = dumbsum(x, y, pattern)\n",
    "    b = dumbsum_vectorized(x, y, pattern)\n",
    "    c = x @ y\n",
    "    assert a.allclose(c)\n",
    "    assert b.allclose(c)\n",
    "\n",
    "dumb_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_test2():\n",
    "    x = t.rand((5, 4, 3, 2))\n",
    "    y = t.rand((5, 4, 3, 2))\n",
    "    pattern = 'a b c d, a b c d -> a b'\n",
    "    a = dumbsum(x, y, pattern)\n",
    "    b = dumbsum_vectorized(x, y, pattern)\n",
    "    c = (x * y).sum((-1, -2))\n",
    "    assert a.allclose(c)\n",
    "    assert b.allclose(c)\n",
    "\n",
    "dumb_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_test3():\n",
    "    x = t.rand((10, 5, 2, 3))\n",
    "    y = t.rand((3, 10, 5, 7))\n",
    "    pattern = 'a b c d, d a b e -> a e'\n",
    "    a = dumbsum(x, y, pattern)\n",
    "    b = dumbsum_vectorized(x, y, pattern)\n",
    "    # align the 2 tensors dimensions\n",
    "    xx = x[..., None] # (a b c d 1)\n",
    "    yy = y[..., None].permute((1, 2, 4, 0, 3)) # (a b 1 d e)\n",
    "    # put the result dims at the start\n",
    "    xx = xx.permute((0, 4, 1, 2, 3)) # (a 1 b c d)\n",
    "    yy = yy.permute((0, 4, 1, 2, 3)) # (a e b 1 d)\n",
    "    c = (xx * yy).sum((2, 3, 4))\n",
    "    assert a.allclose(c)\n",
    "    assert b.allclose(c)\n",
    "\n",
    "dumb_test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def einops_test(x, y, pattern):\n",
    "    a = dumbsum(x, y, pattern)\n",
    "    b = dumbsum_vectorized(x, y, pattern)\n",
    "    c = einops.einsum(x, y, pattern)\n",
    "    assert a.allclose(c)\n",
    "    assert b.allclose(c)\n",
    "\n",
    "x = t.rand((10, 5, 2, 3))\n",
    "y = t.rand((3, 10, 5, 7))\n",
    "einops_test(x, y, 'a b c d, d a b e -> b e c')\n",
    "einops_test(x, y, 'a b c d, d a b e -> a b c d e')\n",
    "einops_test(x, y, 'a b c d, d a b e -> e d c b a')\n",
    "einops_test(x, y, 'a b c d, d a b e -> a')\n",
    "einops_test(x, y, 'a b c d, d a b e ->')\n",
    "einops_test(x, y, 'a b c d, d a b e -> a e')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
